#+TITLE: ghostnote
#+AUTHOR: Tim Loderhose
#+EMAIL: tim@loderhose.com
#+DATE: Wednesday, 11 September 2024
#+STARTUP: showall
#+PROPERTY: header-args :exports both :session gn :kernel gn :cache no
:PROPERTIES:
OPTIONS: ^:nil
#+LATEX_COMPILER: xelatex
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [logo, color, author]
#+LATEX_HEADER: \insertauthor
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage[left=0.75in,top=0.6in,right=0.75in,bottom=0.6in]{geometry}
:END:

* Introduction

Musical onset detection has been studied extensively and for a long time -
robust onset detection exists for a variety of instruments, with methods of
varying accuracy available for both pitched and percussive sounds in and out of
real-time.

This document will discuss ghostnote and onset detection in general at the
example of extracting onset information from a drumset containing multiple
drums and cymbals. These create percussive sounds with sharper transients at
the beginning of the sound, which are easier to detect than sounds like those
generated by e.g. a piano.

The following is a drum hit recorded at 44.1kHz by both a microphone and a
sensor detecting movements of the drumhead:
[[./figures/onset_mic_vs_sensor.png]]
Note that at the onset (around 350 samples) there is some relatively
high-frequency information (fast changes around 0) followed by a big spike.

Compare this to a note played on a piano, also recorded at 44.1kHz:
[[./figures/onset_piano.png]]

We can note that there is more signal remaining from previous notes being
played, and while a change in amplitude is visible, it's much less pronounced
and accompanied by less high-frequency content.

While percussive onsets are clearly easier to detect, the above example was
both a loud hit, and one where sounds from outside the drum weren't present -
in practice onsets can be more difficult to see based on a variety of factors.

* Spectral and amplitude-based onset detection
Different methods of onset detection have different tradeoffs. Generally, we
might say the two biggest categories of approaches are those based in the
*spectral* or *time* domain.

Approaches in the time domain (operating on the raw waveform/amplitude
directly) are fast and often preferred for percussive sounds, as relatively
simple techniques like thresholding on the difference of the recorded signal
might already yield usable onsets. (ref)

Spectral methods start by converting windows of the time-domain signal into
slices of spectra (yielding a spectrogram). Then it's possible to look at the
frequency content of a signal to determine where an onset lies, but there is a
tradeoff between accuracy of frequency and time information, with an inherent
delay in processing related to the size of the processing window. (ref)

Most approaches are based on physical properties of the observed signal and
smart processing thereoff to reveal peaks which can be recorded as onsets once
a threshold is passed. Machine Learning (ML) approaches working (ref) have also
been tried.

* Microphones and sensors
All current methods work on (potentially streaming) single-channel audio/signal
recording the drum(s) of interest being played. Let's focus on use-cases where
near 100% detection accuracy is required, like in the case of electric drums.

//A *microphone* might be sufficient if we only play the drum of interest, and
do this in a quiet environment//. This is because onsets from other sounds
might bleed into the microphone and lead to false onsets. ML might be used to
fingerprint the specific drum, but currently there is no reliable solution
available.

A *sensor* (i.e. membrane sensor or trigger) usually works really well,
as it isolates the signal to contain only the drum of interest, but the
downside is that we need to introduce additional hardware, including the
sensors themselves, but also potentially an (additional) interface.

Neither single sensors nor microphones will be able to accurately position a
hit within a drum or cymbal - while radial information, and, in the sensors
case, information relating to closeness of the hit to the sensing element,
might be learned via fingerprinting or analyzing membrane movement, right or
left are ambiguous.

* Multiple microphones or sensors
Assuming we're working with a fully mic'ed drumkit, we can use the information
of multiple microphones in tandem to both determine the location of hits, and
reject hits which don't originate with a hit.

** Trilateration/Multilateration
*[[https://en.wikipedia.org/wiki/Trilateration][Trilateration]]* (when 3 sensors are involved), or multilateration (for more than
3 sensors), uses the /times of arrival/ of a sound onset at each sensor to
determine where the sound has originated. This technique requires calibration
of sensor/microphone locations, which we can achieve by hitting the drum in
known locations prior to live play.

[[file:multilateration.org][multilateration.org]] goes into detail about this process.

** Location regression
Instead of calibrating sensor locations, we can also use drum hits in known
locations to train ML models like neural networks to learn the location
multi-channel audio data directly.

** Mics vs. Sensors

*** Microphones
*Pro*:
- Drum hit location using existing gear - no need to purchase extra sensors
  - 2 overhead microphones + 1 close microphone are enough to locate hits on a drum
- Usable microphone audio next to predicted location signal
*Con*:
- Overhead microphones are usually over a meter away from the drums - since
  this technique is limited by the speed of sound, this means we incur a
  latency hit of 3ms+ (sound travels through air at about 3ms per meter)
  - the generally accepted limit for live play is 10ms of total latency, which
    means we need very efficient audio processing to make this work at required
    latencies
  
*** Sensors
*Pro*:
- Reliable and mature tech (see Sensory Percussion or simpler triggers)
*Cons*:
- multiple sensors are not feasible for a full drumkit, so no full location information
  - combined use of a single sensor and overhead microphones might be feasible,
    but this needs more work
- additional gear necessary, needs lots of inputs if microphone signal is also required
- currently no sensor solution available for cymbals
  
  
* A new paradigm for processing drums & percussion inside the DAW
Next to the obvious advantages of using microphones for drum hit localization
during live play (if latency can be kept in check), there are also some very
interesting possibilities when considering drum recording and editing in
Digital Audio Workstations (DAWs).

Onset-based editing could make things like gating and drum replacement trivial,
and could allow for new, onset-based workflows. Transcription would be
'built-in', and based on this generated accompaniments would become easier. 
Quantization could also become significantly easier.
